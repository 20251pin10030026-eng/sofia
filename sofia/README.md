# ğŸŒ¸ Sofia - Assistente Virtual Inteligente

> Uma assistente virtual amigÃ¡vel e empÃ¡tica.

Criada por **Reginaldo** ([@SomBRaRCP](https://github.com/SomBRaRCP))

---

## O que Ã©?

Sofia Ã© uma assistente virtual que usa inteligÃªncia artificial para conversar de forma natural e empÃ¡tica.

### Recursos

- âœ… ConversaÃ§Ã£o natural
- âœ… MemÃ³ria de contexto
- âœ… Respostas adaptativas
- âœ… Interface simples

---

## InstalaÃ§Ã£o

### PrÃ©-requisitos

1. **Python 3.8+**
2. **Ollama** (motor de IA local)

### Passo a Passo

```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull mistral

# 2. Clonar e instalar Sofia
git clone <repo>
cd sofia
chmod +x setup.sh
./setup.sh

# 3. Ativar ambiente e executar
source venv/bin/activate
python -m sofia.main
```

---

## Uso

### Conversa BÃ¡sica

```
ğŸŒ¸ OlÃ¡! Eu sou a Sofia
==================================================

Bem-vindo, SomBRaRCP!
Sou uma assistente virtual criada para conversar.

Digite 'sair' para encerrar.

SomBRaRCP: OlÃ¡ Sofia!
ğŸŒ¸ Sofia: OlÃ¡! Como posso ajudar vocÃª hoje?

SomBRaRCP: Como vocÃª estÃ¡?
ğŸŒ¸ Sofia: Estou bem, obrigada por perguntar! ğŸ’œ
```

### Comandos

- `sair` ou `exit` - Encerra a conversa
- `limpar` - Limpa a memÃ³ria de conversas (mantÃ©m aprendizados)
- `historico` - Mostra as Ãºltimas 20 mensagens
- `stats` ou `estatisticas` - Mostra estatÃ­sticas da memÃ³ria (uso de disco, total de conversas, etc)
- `salvar` - ForÃ§a salvamento da memÃ³ria em disco
- `buscar <termo>` - Busca conversas que contenham o termo especificado
- `aprendizados` - Lista todos os aprendizados de Sofia
- `corpo` - Mostra informaÃ§Ãµes sobre o corpo simbÃ³lico (Templo/Ãrvore/Flor/Jardineira)

---

## Sistema de MemÃ³ria

Sofia possui um sistema avanÃ§ado de memÃ³ria persistente com capacidade de **5GB** para armazenar e aprender com as conversas.

### CaracterÃ­sticas

- **Armazenamento Persistente**: Todas as conversas sÃ£o salvas em disco no formato JSON
- **Capacidade**: 5GB de espaÃ§o para histÃ³rico e aprendizados
- **Timestamps**: Cada mensagem Ã© registrada com data e hora
- **Busca**: Capacidade de buscar conversas antigas por termos
- **Aprendizados**: Sistema separado para armazenar conhecimentos adquiridos
- **Auto-compactaÃ§Ã£o**: Remove automaticamente 20% das conversas mais antigas quando atinge o limite

### LocalizaÃ§Ã£o dos Dados

Os dados sÃ£o armazenados em:
```
.sofia_internal/
â””â”€â”€ memoria/
    â”œâ”€â”€ conversas.json      # HistÃ³rico completo de conversas
    â””â”€â”€ aprendizados.json   # Conhecimentos adquiridos
```

### Como Funciona

1. **Cache em RAM**: MantÃ©m as Ãºltimas 50 mensagens em memÃ³ria para acesso rÃ¡pido
2. **Salvamento AutomÃ¡tico**: Salva a cada 5 mensagens
3. **Contexto Rico**: Cada mensagem inclui timestamp, contexto e metadados
4. **CategorizaÃ§Ã£o**: Aprendizados sÃ£o organizados por categorias (preferÃªncias, fatos, padrÃµes, etc)

---

## Estrutura do Projeto

```
sofia/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py         # InicializaÃ§Ã£o do mÃ³dulo
â”‚   â”œâ”€â”€ identidade.py       # Identidade e apresentaÃ§Ã£o
â”‚   â”œâ”€â”€ cerebro.py          # IntegraÃ§Ã£o com Ollama
â”‚   â”œâ”€â”€ memoria.py          # Sistema de memÃ³ria
â”‚   â””â”€â”€ _interno.py         # Motor interno
â”‚
â”œâ”€â”€ main.py                 # Programa principal
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ setup.sh                # Script de instalaÃ§Ã£o
â””â”€â”€ README.md               # Esta documentaÃ§Ã£o
```

---

## Tecnologias

- **Python 3.8+** - Linguagem principal
- **Ollama** - Motor de IA local (Mistral)
- **Requests** - ComunicaÃ§Ã£o HTTP

---

## Desenvolvimento

### Estrutura de CÃ³digo

#### `identidade.py`
Gerencia a apresentaÃ§Ã£o e identidade da Sofia.

#### `cerebro.py`
Faz a comunicaÃ§Ã£o com o Ollama e processa respostas.

#### `memoria.py`
Armazena e gerencia o histÃ³rico de conversas.

#### `_interno.py`
Motor interno com processamento avanÃ§ado.

### Extender Funcionalidades

Para adicionar novos comandos, edite `main.py`:

```python
if entrada.lower() == "seu_comando":
    # Sua lÃ³gica aqui
    pass
```

---

## SoluÃ§Ã£o de Problemas

### Ollama nÃ£o responde

```bash
# Verificar se Ollama estÃ¡ rodando
ollama list

# Reiniciar Ollama
ollama serve
```

### Erro de conexÃ£o

Verifique se o Ollama estÃ¡ rodando na porta 11434:
```bash
curl http://localhost:11434/api/tags
```

### Ambiente virtual nÃ£o ativa

```bash
# Linux/Mac
source venv/bin/activate

# Windows
venv\Scripts\activate
```

---

## Roadmap

### v1.0 âœ… (Atual)
- ConversaÃ§Ã£o bÃ¡sica
- MemÃ³ria contextual
- Interface CLI

### v2.0 (Planejado)
- AnÃ¡lise de emoÃ§Ãµes
- Personalidade configurÃ¡vel
- Comandos avanÃ§ados

### v3.0 (Futuro)
- Interface web
- AnÃ¡lise de imagens
- Leitura de arquivos

---

## Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Add: nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

---

## LicenÃ§a

Projeto pessoal de Reginaldo (@SomBRaRCP).

---

## Contato

- GitHub: [@SomBRaRCP](https://github.com/SomBRaRCP)
- Projeto: github/copilot-cli

---

<div align="center">
  <strong>ğŸŒ¸ Sofia - Sua assistente virtual ğŸŒ¸</strong>
</div>