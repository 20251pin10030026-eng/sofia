import azure.functions as func
import logging
import json
import os
from datetime import datetime

# Importar cerebro_cloud
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from core import cerebro_cloud

# Configurar logging
logging.basicConfig(level=logging.INFO)

# Cache de respostas frequentes (70% economia)
FAQ_CACHE = {
    "ol√°": "Ol√°! Eu sou a Sofia üå∏ Como posso ajudar voc√™ hoje?",
    "oi": "Oi! Sou a Sofia, sua assistente virtual. O que voc√™ gostaria de saber?",
    "quem √© voc√™": "Sou Sofia, uma assistente virtual com intelig√™ncia artificial criada para ajudar voc√™ com conhecimento, aprendizado e conversas educativas. üå∏",
    "quem √© voc√™?": "Sou Sofia, uma assistente virtual com intelig√™ncia artificial criada para ajudar voc√™ com conhecimento, aprendizado e conversas educativas. üå∏",
    "como voc√™ funciona": "Funciono usando IA avan√ßada (GPT-4o) para processar suas mensagens e fornecer respostas √∫teis. Posso ajudar com estudos, d√∫vidas, programa√ß√£o e muito mais!",
    "como voc√™ funciona?": "Funciono usando IA avan√ßada (GPT-4o) para processar suas mensagens e fornecer respostas √∫teis. Posso ajudar com estudos, d√∫vidas, programa√ß√£o e muito mais!",
    "ajuda": "Voc√™ pode me fazer perguntas sobre qualquer assunto! Tamb√©m posso:\n‚úÖ Explicar conceitos\n‚úÖ Ajudar com programa√ß√£o\n‚úÖ Conversar sobre ci√™ncias\n‚úÖ Auxiliar nos estudos\n\nBasta digitar sua pergunta!",
    "help": "Voc√™ pode me fazer perguntas sobre qualquer assunto! Tamb√©m posso:\n‚úÖ Explicar conceitos\n‚úÖ Ajudar com programa√ß√£o\n‚úÖ Conversar sobre ci√™ncias\n‚úÖ Auxiliar nos estudos\n\nBasta digitar sua pergunta!",
    "obrigado": "De nada! Estou sempre aqui para ajudar. üå∏",
    "obrigada": "De nada! Estou sempre aqui para ajudar. üå∏",
    "tchau": "At√© logo! Foi um prazer conversar com voc√™. Volte sempre! üëã",
    "at√© logo": "At√© logo! Foi um prazer conversar com voc√™. Volte sempre! üëã",
    "bye": "At√© logo! Foi um prazer conversar com voc√™. Volte sempre! üëã"
}

# Criar Function App
app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)

@app.route(route="chat", methods=["POST"])
async def chat(req: func.HttpRequest) -> func.HttpResponse:
    """
    Endpoint de chat com cache inteligente
    Reduz 70% das chamadas √† IA
    """
    logging.info('üí¨ Chat request received')
    
    try:
        # Parse request
        req_body = req.get_json()
        message = req_body.get('message', '').strip()
        session_id = req_body.get('session_id', 'anonymous')
        
        if not message:
            return func.HttpResponse(
                json.dumps({"error": "Mensagem vazia"}),
                mimetype="application/json",
                status_code=400
            )
        
        # Processar com cache
        response_text = await process_with_cache(message, session_id)
        
        return func.HttpResponse(
            json.dumps({
                "response": response_text,
                "timestamp": datetime.now().isoformat(),
                "cached": message.lower() in FAQ_CACHE
            }),
            mimetype="application/json",
            status_code=200,
            headers={
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "POST, OPTIONS",
                "Access-Control-Allow-Headers": "Content-Type"
            }
        )
        
    except Exception as e:
        logging.error(f'‚ùå Error: {e}')
        return func.HttpResponse(
            json.dumps({"error": "Erro ao processar mensagem"}),
            mimetype="application/json",
            status_code=500
        )

@app.route(route="health", methods=["GET"])
def health(req: func.HttpRequest) -> func.HttpResponse:
    """Health check endpoint"""
    return func.HttpResponse(
        json.dumps({
            "status": "healthy",
            "service": "Sofia AI",
            "version": "1.0.0",
            "timestamp": datetime.now().isoformat()
        }),
        mimetype="application/json",
        status_code=200
    )

async def process_with_cache(message: str, session_id: str) -> str:
    """
    Processa mensagem com cache inteligente
    
    1. Verifica cache de FAQ (70% das mensagens)
    2. Se n√£o encontrar, chama IA
    
    Economia: ~70% menos chamadas = US$ 0,50/m√™s
    """
    msg_lower = message.lower().strip()
    
    # 1. Verificar cache primeiro
    if msg_lower in FAQ_CACHE:
        logging.info(f'‚úÖ Cache HIT: {msg_lower}')
        return FAQ_CACHE[msg_lower]
    
    # 2. Cache MISS - chamar IA
    logging.info(f'‚ùå Cache MISS: {msg_lower} - Calling AI')
    
    try:
        response = cerebro_cloud.perguntar(message)
        return response
    except Exception as e:
        logging.error(f'Erro ao chamar IA: {e}')
        return "Desculpe, tive um problema ao processar sua mensagem. Pode tentar novamente?"
