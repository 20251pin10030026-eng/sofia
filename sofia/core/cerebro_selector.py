"""
ğŸŒ¸ Sofia - Seletor de CÃ©rebro
Escolhe automaticamente entre Ollama (local) ou GitHub Models (cloud)
baseado nas variÃ¡veis de ambiente
"""

import os

# Detectar ambiente
USE_CLOUD = os.getenv("SOFIA_USE_CLOUD", "false").lower() == "true"
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "")

# Importar cerebro apropriado
if USE_CLOUD or GITHUB_TOKEN:
    print("ğŸŒ Sofia rodando em modo CLOUD (GitHub Models)")
    from .cerebro_cloud import perguntar
else:
    print("ğŸ  Sofia rodando em modo LOCAL (Ollama)")
    from .cerebro import perguntar

# Exportar funÃ§Ã£o perguntar
__all__ = ['perguntar']
