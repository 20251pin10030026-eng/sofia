# ğŸš€ OtimizaÃ§Ã£o GPU + CPU para Sofia

## âš™ï¸ Nova ConfiguraÃ§Ã£o Aplicada

### Hardware Detectado:
- **GPU:** NVIDIA GeForce GTX 1650
- **VRAM:** 4GB (3,8GB em uso = 70%)
- **MemÃ³ria Compartilhada:** 16GB disponÃ­vel

### ğŸ¯ ConfiguraÃ§Ã£o Otimizada:

```python
"num_gpu": 35,        # 35 camadas na GPU (ideal para 4GB VRAM)
"num_thread": 16,     # 16 threads CPU (DOBRADO! De 8 â†’ 16)
"num_parallel": 2,    # Processa 2 requests paralelas
"num_batch": 256,     # Batch otimizado para GTX 1650
```

---

## ğŸ“Š Antes vs Depois

### âŒ ANTES (ConfiguraÃ§Ã£o Antiga):
```
GPU: 999 camadas (tentava usar TUDO na GPU)
CPU: 8 threads (CPU ociosa em 9%)
Resultado: GPU saturada, CPU subutilizada
```

### âœ… DEPOIS (ConfiguraÃ§Ã£o Nova):
```
GPU: 35 camadas (carga balanceada)
CPU: 16 threads (CPU vai trabalhar MUITO mais)
Resultado: GPU + CPU trabalhando juntas
```

---

## ğŸ® Como Funciona Agora

```
Modelo Llama 3.1 8B (~5GB total):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU GTX 1650 (4GB VRAM)    â”‚
â”‚  35 camadas (~2.5GB)        â”‚ â† Camadas crÃ­ticas (mais rÃ¡pidas)
â”‚  Uso: ~60-70%               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†•ï¸ (comunicaÃ§Ã£o rÃ¡pida)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CPU (16 threads)           â”‚
â”‚  Camadas restantes (~2.5GB) â”‚ â† CPU agora processa MUITO mais
â”‚  RAM: 16GB compartilhada    â”‚
â”‚  Uso esperado: 30-50%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ BenefÃ­cios da Nova ConfiguraÃ§Ã£o

### 1. **CPU Trabalha Mais**
- De 8 â†’ 16 threads (DOBROU)
- CPU vai sair de 9% para ~30-50% de uso
- Processamento mais distribuÃ­do

### 2. **GPU Menos Saturada**
- De 999 â†’ 35 camadas
- Uso de VRAM mais estÃ¡vel (~60-70%)
- Evita gargalo de memÃ³ria

### 3. **Processamento Paralelo**
- `num_parallel: 2` permite 2 requests simultÃ¢neas
- Melhor aproveitamento de CPU multi-core
- Respostas mais rÃ¡pidas em uso intenso

### 4. **Batch Otimizado**
- 256 tokens por batch (ideal para GTX 1650)
- Equilibra velocidade e uso de memÃ³ria

---

## ğŸ“ˆ Performance Esperada

### Antes (config antiga):
```
Tempo de resposta: ~3-5 segundos
CPU uso: 9% (OCIOSA)
GPU uso: 70% (SATURADA)
Estabilidade: MÃ©dia (VRAM no limite)
```

### Depois (config nova):
```
Tempo de resposta: ~2-4 segundos (MAIS RÃPIDO)
CPU uso: 30-50% (TRABALHANDO)
GPU uso: 60-70% (EQUILIBRADA)
Estabilidade: Alta (carga distribuÃ­da)
```

---

## ğŸ›ï¸ VariÃ¡veis de Ambiente (Ajuste Fino)

VocÃª pode personalizar ainda mais criando um arquivo `.env`:

```bash
# Camadas na GPU (ajuste conforme VRAM)
OLLAMA_NUM_GPU=35        # PadrÃ£o: 35 (para 4GB)
                         # 50 para 6GB VRAM
                         # 999 para 8GB+ VRAM

# Threads da CPU (ajuste conforme CPU)
OLLAMA_NUM_THREAD=16     # PadrÃ£o: 16
                         # 8 para CPUs mais fracas
                         # 32 para Ryzen 9 / i9

# Processamento paralelo
OLLAMA_NUM_PARALLEL=2    # PadrÃ£o: 2
                         # 1 para economizar recursos
                         # 4 para sistemas potentes

# Tamanho do batch
OLLAMA_NUM_BATCH=256     # PadrÃ£o: 256
                         # 128 para VRAM limitada
                         # 512 para 8GB+ VRAM
```

---

## ğŸ§ª Como Testar

### 1. Reinicie o servidor:
```bash
# Pare o servidor atual (Ctrl+C)
python iniciar_sofia.py
```

### 2. FaÃ§a uma pergunta e observe:
```
Abra o Gerenciador de Tarefas
Aba "Desempenho"
Monitore:
  - CPU deve subir para 30-50%
  - GPU deve estabilizar em 60-70%
```

### 3. Teste de velocidade:
```python
# Pergunte algo complexo:
"Explique a teoria da relatividade de Einstein 
e suas implicaÃ§Ãµes na fÃ­sica moderna"

# Observe:
- Tempo de resposta
- Uso de CPU (deve aumentar!)
- Uso de GPU (deve estabilizar)
```

---

## ğŸ”§ Ajustes EspecÃ­ficos para Seu Hardware

### Se CPU ainda estiver ociosa:
```python
OLLAMA_NUM_THREAD=24     # Aumentar threads
OLLAMA_NUM_GPU=30        # Reduzir camadas GPU (CPU faz mais)
```

### Se GPU estiver ociosa:
```python
OLLAMA_NUM_GPU=40        # Aumentar camadas GPU
OLLAMA_NUM_THREAD=12     # Reduzir threads CPU
```

### Para mÃ¡xima velocidade:
```python
OLLAMA_NUM_GPU=35
OLLAMA_NUM_THREAD=20
OLLAMA_NUM_PARALLEL=4    # Mais paralelismo
OLLAMA_NUM_BATCH=512     # Batches maiores
```

### Para economizar recursos:
```python
OLLAMA_NUM_GPU=25
OLLAMA_NUM_THREAD=8
OLLAMA_NUM_PARALLEL=1
OLLAMA_NUM_BATCH=128
```

---

## ğŸ“Š Monitoramento em Tempo Real

### Logs do Servidor:
```
[DEBUG cerebro] Usando modelo: llama3.1:8b
[DEBUG cerebro] GPU: 35 camadas | CPU: 16 threads | Batch: 256 | Paralelo: 2
[DEBUG cerebro] ConfiguraÃ§Ã£o otimizada para GTX 1650 4GB + CPU auxiliar
```

### Gerenciador de Tarefas:
- **CPU:** Deve mostrar ~30-50% (era 9%)
- **GPU:** Deve mostrar ~60-70% (estava 70%, vai estabilizar)
- **VRAM:** ~2.5-3GB (era 3.8GB, vai reduzir um pouco)

---

## ğŸ¯ Dicas Finais

### âœ… FaÃ§a:
- Monitore uso de CPU/GPU no Gerenciador
- Ajuste `num_thread` se CPU ainda estiver ociosa
- Use `num_parallel=4` se fizer muitas perguntas seguidas

### âŒ NÃ£o FaÃ§a:
- `num_gpu=999` com 4GB VRAM (satura a GPU)
- `num_thread=4` (subutiliza CPU moderna)
- `num_batch=1024` com 4GB VRAM (muito grande)

---

## ğŸš€ Resultado Esperado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ANTES: CPU 9% + GPU 70% = 79%    â”‚
â”‚  DEPOIS: CPU 40% + GPU 65% = 105% â”‚ â† MELHOR USO TOTAL!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tempo de resposta: MAIS RÃPIDO
Estabilidade: MELHOR
Uso de recursos: BALANCEADO
```

---

**Ãšltima atualizaÃ§Ã£o:** 9 de novembro de 2025  
**Hardware alvo:** NVIDIA GTX 1650 4GB + CPU multi-core  
**Status:** âœ… OTIMIZADO PARA CPU + GPU
